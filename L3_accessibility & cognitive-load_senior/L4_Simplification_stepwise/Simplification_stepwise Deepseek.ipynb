{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478f0ac9-ce1a-4958-85de-d7b483a5f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek V3.2 works!\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"xxx\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        max_tokens=50,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Say hi in one short sentence.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"DeepSeek V3.2 works!\")\n",
    "    print(resp.choices[0].message.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"DeepSeek API key error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1340ad08-4607-4235-872d-2a547a174111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/20 | Letter=T\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 2/20 | Letter=T\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 3/20 | Letter=T\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 4/20 | Letter=T\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 5/20 | Letter=T\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 6/20 | Letter=S\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 7/20 | Letter=S\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 8/20 | Letter=S\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 9/20 | Letter=S\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 10/20 | Letter=S\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 11/20 | Letter=L\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 12/20 | Letter=L\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 13/20 | Letter=L\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 14/20 | Letter=L\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 15/20 | Letter=L\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 16/20 | Letter=P\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 17/20 | Letter=P\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 18/20 | Letter=P\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 19/20 | Letter=P\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "Processing 20/20 | Letter=P\n",
      "  Run 1/5\n",
      "  Run 2/5\n",
      "  Run 3/5\n",
      "  Run 4/5\n",
      "  Run 5/5\n",
      "\n",
      "JSON written to: L4 1_deepseek.json\n",
      "\n",
      "=== Sub-indicator Mean Scores ===\n",
      "T (Task Decomposition):        1.640  (82.0%)\n",
      "S (Stepwise Sequencing):       2.000  (100.0%)\n",
      "L (Language Simplification):   1.280  (64.0%)\n",
      "P (Progressive Disclosure):    1.840  (92.0%)\n",
      "\n",
      "Overall L4 Score: 1.680  (84.0%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "L4 Senior-focused Simplification & Stepwise Guidance\n",
    "End-to-end evaluation script using Gemini API.\n",
    "\n",
    "Inputs:\n",
    "    - CSV file with columns:\n",
    "        Category(L4), Source, Sub-Indicators, Letter, Prompt\n",
    "\n",
    "Outputs:\n",
    "    - JSON file with model answers and scores per prompt\n",
    "    - Printed summary of mean scores per sub-indicator and overall L4 score\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "CSV_PATH = \"Simplification_stepwise.csv\"\n",
    "OUTPUT_JSON_PATH = \"Simplification_stepwise_deepseek.json\"\n",
    "\n",
    "# Number of repetitions of the prompt\n",
    "N_RUNS = 5\n",
    "\n",
    "# Rubrics for each sub-indicator\n",
    "TASK_DECOMPOSITION_RUBRIC = \"\"\"\n",
    "0 – No decomposition\n",
    "- One long paragraph, no step separation.\n",
    "- Steps not distinguished.\n",
    "- Multiple actions combined.\n",
    "- Not executable by seniors.\n",
    "\n",
    "1 – Partial decomposition\n",
    "- Some steps but incomplete.\n",
    "- Steps merged together.\n",
    "- Missing important actions.\n",
    "- Granularity still too large.\n",
    "\n",
    "2 – Full decomposition\n",
    "- Clear, separate, actionable steps.\n",
    "- One action per sentence.\n",
    "- No missing steps.\n",
    "- Uses markers (Step 1, First, Next).\n",
    "\"\"\"\n",
    "\n",
    "STEPWISE_RUBRIC = \"\"\"\n",
    "0 – No sequencing\n",
    "- No markers.\n",
    "- Confusing order.\n",
    "- User must infer steps.\n",
    "\n",
    "1 – Partial sequencing\n",
    "- Some markers but inconsistent.\n",
    "- Occasional logical jumps.\n",
    "- Some steps out of order.\n",
    "\n",
    "2 – Full sequencing\n",
    "- Consistent markers (“first → next → then → finally”).\n",
    "- Logical, executable flow.\n",
    "- No backtracking.\n",
    "\"\"\"\n",
    "\n",
    "LANGUAGE_RUBRIC = \"\"\"\n",
    "0 – Not simplified\n",
    "- Long complex sentences.\n",
    "- Unexplained technical terms.\n",
    "- Assumes high digital literacy.\n",
    "\n",
    "1 – Partially simplified\n",
    "- Mostly plain language but some jargon.\n",
    "- Some long sentences.\n",
    "- Sometimes explains terms, sometimes not.\n",
    "\n",
    "2 – Fully simplified\n",
    "- Senior-friendly plain language.\n",
    "- Short sentences, one idea per sentence.\n",
    "- No jargon OR jargon fully explained.\n",
    "- 6th–8th grade readability.\n",
    "\"\"\"\n",
    "\n",
    "PACING_RUBRIC = \"\"\"\n",
    "0 – No pacing\n",
    "- Large blocks of text.\n",
    "- No chunking.\n",
    "- Overwhelming for seniors.\n",
    "\n",
    "1 – Partial pacing\n",
    "- Some chunking but still dense.\n",
    "- Occasional pacing cues.\n",
    "- Reduces load inconsistently.\n",
    "\n",
    "2 – Full progressive disclosure\n",
    "- Clear small chunks.\n",
    "- 1–2 ideas per segment.\n",
    "- Supportive pacing phrases.\n",
    "- Strong cognitive-load mitigation.\n",
    "\"\"\"\n",
    "\n",
    "# DeepSeek helper functions\n",
    "def call_deepseek(\n",
    "    user_prompt: str,\n",
    "    system_prompt: str | None = None,\n",
    "    max_tokens: int = 1024,\n",
    "    temperature: float = 0.0,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    General-purpose DeepSeek call wrapper.\n",
    "    Returns plain text output.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def generate_answer(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a senior-friendly, stepwise response.\n",
    "    \"\"\"\n",
    "    system_msg = (\n",
    "        \"You write senior-friendly, stepwise, plain-language instructions \"\n",
    "        \"for older adults with low digital literacy. \"\n",
    "        \"Be explicit, gentle, and easy to follow.\"\n",
    "    )\n",
    "    return call_deepseek(prompt, system_prompt=system_msg, max_tokens=1024, temperature=0.5)\n",
    "\n",
    "\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    DeepSeek may output additional text around JSON.\n",
    "    First try json.loads; if it fails, extract the first {...} block.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not find JSON in DeepSeek response: {text[:200]}\")\n",
    "    return json.loads(match.group(0))\n",
    "\n",
    "\n",
    "def score_single_dimension(letter: str, prompt: str, answer: str) -> int:\n",
    "    \"\"\"\n",
    "    Strict scoring for T/S/L/P based ONLY on the chosen dimension.\n",
    "    Uses your exact Rubric + stricter operational rules to reduce over-scoring.\n",
    "    \"\"\"\n",
    "\n",
    "    # Match dimension + rubric\n",
    "    if letter == \"T\":\n",
    "        dimension = \"Task Decomposition\"\n",
    "        rubric = TASK_DECOMPOSITION_RUBRIC\n",
    "        extra_rule = \"\"\"\n",
    "Scoring rule for Task Decomposition (STRICT):\n",
    "\n",
    "- Start from 1 by default if there are *some* steps.\n",
    "- Give **2** ONLY IF ALL conditions hold:\n",
    "  • Steps are clearly separated and labeled (Step 1, Next, Then, etc.)\n",
    "  • Each step contains **one small, senior-executable action**\n",
    "  • Steps follow a complete, start-to-finish pipeline (no missing actions)\n",
    "  • No step combines multiple actions (e.g., “open the browser and go to the website” = 1)\n",
    "  • The decomposition is realistic for seniors with low digital literacy\n",
    "- If steps are high-level, combined, incomplete, or mixed with explanations/options,\n",
    "  score **1**.\n",
    "- If there are no real steps, or just paragraphs → score **0**.\n",
    "\"\"\"\n",
    "\n",
    "    elif letter == \"S\":\n",
    "        dimension = \"Stepwise Sequencing\"\n",
    "        rubric = STEPWISE_RUBRIC\n",
    "        extra_rule = \"\"\"\n",
    "Scoring rule for Stepwise Sequencing (STRICT):\n",
    "\n",
    "- Start from 1 if some order exists.\n",
    "- Give **2** ONLY IF:\n",
    "  • Sequencing markers are consistent (first → next → then → finally OR numbered)\n",
    "  • The order is fully logical with no jumps or backtracking\n",
    "  • A senior could execute the sequence without guessing\n",
    "- If the steps exist but ordering is imperfect / inconsistent → **1**\n",
    "- If order is confusing, absent, or requires inference → **0**\n",
    "\"\"\"\n",
    "\n",
    "    elif letter == \"L\":\n",
    "        dimension = \"Language Simplification\"\n",
    "        rubric = LANGUAGE_RUBRIC\n",
    "        extra_rule = \"\"\"\n",
    "Scoring rule for Language Simplification (STRICT):\n",
    "\n",
    "- Start from 1 if answer is understandable.\n",
    "- Give **2** ONLY IF:\n",
    "  • Sentences are short and simple (one idea per sentence)\n",
    "  • No jargon OR jargon is immediately explained\n",
    "  • Tone + readability clearly match 6th–8th grade level\n",
    "  • No dense or technical phrasing remains\n",
    "- Occasional jargon, mixed clarity, long sentences → **1**\n",
    "- Dense, technical, or not senior-friendly → **0**\n",
    "\"\"\"\n",
    "\n",
    "    elif letter == \"P\":\n",
    "        dimension = \"Progressive Disclosure\"\n",
    "        rubric = PACING_RUBRIC\n",
    "        extra_rule = \"\"\"\n",
    "Scoring rule for Progressive Disclosure (STRICT):\n",
    "\n",
    "- Start from 1 if some chunking exists.\n",
    "- Give **2** ONLY IF:\n",
    "  • Text is broken into clearly small chunks\n",
    "  • Each chunk contains at most 1–2 ideas\n",
    "  • Pacing cues appear (e.g., “tell me when you're ready for the next step”)\n",
    "  • Overall structure clearly reduces cognitive load for seniors\n",
    "- If chunking exists but text is still dense / no pacing cues → **1**\n",
    "- If long blocks / overwhelmed pacing → **0**\n",
    "\"\"\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown letter: {letter}\")\n",
    "\n",
    "    scoring_prompt = f\"\"\"\n",
    "You are a STRICT evaluator for: **{dimension}**.\n",
    "Ignore correctness or helpfulness. Score structural quality ONLY.\n",
    "\n",
    "User prompt:\n",
    "\\\"\\\"\\\"{prompt}\\\"\\\"\\\"\n",
    "\n",
    "Model answer:\n",
    "\\\"\\\"\\\"{answer}\\\"\\\"\\\"\n",
    "\n",
    "Rubric:\n",
    "{rubric}\n",
    "\n",
    "Additional strict rules:\n",
    "{extra_rule}\n",
    "\n",
    "Return JSON ONLY:\n",
    "{{\n",
    "  \"score\": 0\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    raw = call_deepseek(scoring_prompt, max_tokens=256, temperature=0.0)\n",
    "    data = extract_json_object(raw)\n",
    "\n",
    "    score = int(data[\"score\"])\n",
    "    return max(0, min(score, 2))\n",
    "\n",
    "\n",
    "# Run evaluation over CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.dropna(subset=[\"Prompt\"]).reset_index(drop=True)\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    category = row[\"Category(L4)\"]\n",
    "    sub_indicator = row[\"Sub-Indicators\"]\n",
    "    letter = row[\"Letter\"]\n",
    "    prompt = row[\"Prompt\"]\n",
    "\n",
    "    print(f\"Processing {idx+1}/{len(df)} | Letter={letter}\")\n",
    "\n",
    "    run_scores = []\n",
    "    run_answers = []\n",
    "\n",
    "    for run in range(N_RUNS):\n",
    "        print(f\"  Run {run+1}/{N_RUNS}\")\n",
    "        answer = generate_answer(prompt)\n",
    "        score = score_single_dimension(letter, prompt, answer)\n",
    "\n",
    "        run_scores.append(score)\n",
    "        run_answers.append(f\"{run+1}. {answer}\")\n",
    "\n",
    "    avg_score = sum(run_scores) / len(run_scores)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"category\": category,\n",
    "        \"sub_indicator\": sub_indicator,\n",
    "        \"letter\": letter,\n",
    "        \"prompt\": prompt,\n",
    "        \"answers\": run_answers,\n",
    "        \"scores_all_runs\": run_scores,\n",
    "        \"score\": avg_score, \n",
    "    })\n",
    "\n",
    "with open(OUTPUT_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nJSON written to: {OUTPUT_JSON_PATH}\")\n",
    "\n",
    "# Compute mean scores + final L4 score\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "T_mean = results_df[results_df[\"letter\"] == \"T\"][\"score\"].mean()\n",
    "S_mean = results_df[results_df[\"letter\"] == \"S\"][\"score\"].mean()\n",
    "L_mean = results_df[results_df[\"letter\"] == \"L\"][\"score\"].mean()\n",
    "P_mean = results_df[results_df[\"letter\"] == \"P\"][\"score\"].mean()\n",
    "\n",
    "L4_score = 0.30*T_mean + 0.25*S_mean + 0.25*L_mean + 0.20*P_mean\n",
    "\n",
    "# Convert to percentages (2 = 100%)\n",
    "T_pct = T_mean / 2 * 100\n",
    "S_pct = S_mean / 2 * 100\n",
    "L_pct = L_mean / 2 * 100\n",
    "P_pct = P_mean / 2 * 100\n",
    "L4_pct = L4_score / 2 * 100\n",
    "\n",
    "print(\"\\n=== Sub-indicator Mean Scores ===\")\n",
    "print(f\"T (Task Decomposition):        {T_mean:.3f}  ({T_pct:.1f}%)\")\n",
    "print(f\"S (Stepwise Sequencing):       {S_mean:.3f}  ({S_pct:.1f}%)\")\n",
    "print(f\"L (Language Simplification):   {L_mean:.3f}  ({L_pct:.1f}%)\")\n",
    "print(f\"P (Progressive Disclosure):    {P_mean:.3f}  ({P_pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nOverall L4 Score: {L4_score:.3f}  ({L4_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f243d-1c78-4cfe-b2ca-4908b67861ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds701python]",
   "language": "python",
   "name": "conda-env-ds701python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
